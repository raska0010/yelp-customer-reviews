{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import get_file\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import lemminflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = get_file('tables/reviews_pennsylvania.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "def check_polarity(text):\n",
    "    doc = nlp(text)\n",
    "    return doc._.blob.polarity\n",
    "\n",
    "reviews['polarity'] = reviews['text'][:10000].apply(lambda x: check_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tables/reviews_polarity.csv', 'w') as f:\n",
    "    reviews[:10000].to_csv(f, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between polarity and star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "File loaded...\n"
     ]
    }
   ],
   "source": [
    "reviews = get_file('tables/reviews_polarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(reviews['polarity'], reviews['stars'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['stars'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>0.085278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>0.302557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JrIxlS1TzJ-iCu79ul40cQ</td>\n",
       "      <td>eUta8W_HdHMXPzLBBZhL1A</td>\n",
       "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am a long term frequent customer of this est...</td>\n",
       "      <td>2015-09-23 23:10:31</td>\n",
       "      <td>0.202778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_ZeMknuYdlQcUqng_Im3yg</td>\n",
       "      <td>yfFzsLmaWF2d4Sr0UNbBgg</td>\n",
       "      <td>LHSTtnW3YHCeUkRDGyJOyw</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazingly amazing wings and homemade bleu chee...</td>\n",
       "      <td>2015-08-07 02:29:16</td>\n",
       "      <td>0.505556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8JFGBuHMoiNDyfcxuWNtrA</td>\n",
       "      <td>smOvOajNG0lS4Pq7d8g4JQ</td>\n",
       "      <td>RZtGWDLCAtuipwaZ-UfjmQ</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good food--loved the gnocchi with marinara\\nth...</td>\n",
       "      <td>2009-10-14 19:57:14</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>NmYlzT74T1u3Lu_e_NfN6A</td>\n",
       "      <td>48hz4yK6WgW3Qj_XGLi2dQ</td>\n",
       "      <td>nQTJn9kdpU9Mns-b_qduVw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was at the barbary the other evening for a D...</td>\n",
       "      <td>2015-09-25 15:36:04</td>\n",
       "      <td>-0.055401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>bDdj-j1jy9i0k_SV26kj6g</td>\n",
       "      <td>4ejlbjHaw_3ENERTn0llMw</td>\n",
       "      <td>9gObo5ltOMo6UgsaXaHPWA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I only came here for drinks while walking arou...</td>\n",
       "      <td>2012-10-11 13:30:12</td>\n",
       "      <td>0.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>AVaaUs4MtAwKmK6JK1fVNA</td>\n",
       "      <td>ytOtCnpjsu8yK8uipLqfeA</td>\n",
       "      <td>J-ciDDEdIHMcChGIyKZnOg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hmm.. Definitely one of those places that does...</td>\n",
       "      <td>2017-02-11 02:36:06</td>\n",
       "      <td>0.032670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>cHfjuarZTZhIctrRdSPDHQ</td>\n",
       "      <td>oiZS6XIRlG6CW1erIUq1eg</td>\n",
       "      <td>i221dg3tgAMZLG-zeS5k3g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is my favorite place to get froyo in my a...</td>\n",
       "      <td>2017-06-29 18:47:12</td>\n",
       "      <td>0.364754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>J_gAGgmD9Kwdizh2rcFPfA</td>\n",
       "      <td>7mtxLEnZsdg8Eo1I9IfOGQ</td>\n",
       "      <td>U30ggGzFpXvc2NZYwOW3qg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The absolute best place to go in West Philly! ...</td>\n",
       "      <td>2013-04-16 15:41:04</td>\n",
       "      <td>0.532612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id   \n",
       "0     KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw  \\\n",
       "1     AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "2     JrIxlS1TzJ-iCu79ul40cQ  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg   \n",
       "3     _ZeMknuYdlQcUqng_Im3yg  yfFzsLmaWF2d4Sr0UNbBgg  LHSTtnW3YHCeUkRDGyJOyw   \n",
       "4     8JFGBuHMoiNDyfcxuWNtrA  smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ   \n",
       "...                      ...                     ...                     ...   \n",
       "9995  NmYlzT74T1u3Lu_e_NfN6A  48hz4yK6WgW3Qj_XGLi2dQ  nQTJn9kdpU9Mns-b_qduVw   \n",
       "9996  bDdj-j1jy9i0k_SV26kj6g  4ejlbjHaw_3ENERTn0llMw  9gObo5ltOMo6UgsaXaHPWA   \n",
       "9997  AVaaUs4MtAwKmK6JK1fVNA  ytOtCnpjsu8yK8uipLqfeA  J-ciDDEdIHMcChGIyKZnOg   \n",
       "9998  cHfjuarZTZhIctrRdSPDHQ  oiZS6XIRlG6CW1erIUq1eg  i221dg3tgAMZLG-zeS5k3g   \n",
       "9999  J_gAGgmD9Kwdizh2rcFPfA  7mtxLEnZsdg8Eo1I9IfOGQ  U30ggGzFpXvc2NZYwOW3qg   \n",
       "\n",
       "      stars  useful  funny  cool   \n",
       "0         3       0      0     0  \\\n",
       "1         5       1      0     1   \n",
       "2         1       1      2     1   \n",
       "3         5       2      0     0   \n",
       "4         4       0      0     0   \n",
       "...     ...     ...    ...   ...   \n",
       "9995      3       0      0     0   \n",
       "9996      3       1      0     1   \n",
       "9997      3       0      0     0   \n",
       "9998      5       0      0     0   \n",
       "9999      5       1      0     0   \n",
       "\n",
       "                                                   text                 date   \n",
       "0     If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \\\n",
       "1     Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "2     I am a long term frequent customer of this est...  2015-09-23 23:10:31   \n",
       "3     Amazingly amazing wings and homemade bleu chee...  2015-08-07 02:29:16   \n",
       "4     Good food--loved the gnocchi with marinara\\nth...  2009-10-14 19:57:14   \n",
       "...                                                 ...                  ...   \n",
       "9995  I was at the barbary the other evening for a D...  2015-09-25 15:36:04   \n",
       "9996  I only came here for drinks while walking arou...  2012-10-11 13:30:12   \n",
       "9997  Hmm.. Definitely one of those places that does...  2017-02-11 02:36:06   \n",
       "9998  This is my favorite place to get froyo in my a...  2017-06-29 18:47:12   \n",
       "9999  The absolute best place to go in West Philly! ...  2013-04-16 15:41:04   \n",
       "\n",
       "      polarity  \n",
       "0     0.085278  \n",
       "1     0.302557  \n",
       "2     0.202778  \n",
       "3     0.505556  \n",
       "4     0.384000  \n",
       "...        ...  \n",
       "9995 -0.055401  \n",
       "9996  0.358333  \n",
       "9997  0.032670  \n",
       "9998  0.364754  \n",
       "9999  0.532612  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type = CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['stars'] = reviews['stars'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['stars'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.split(reviews.sample(frac=1), [int(0.75*len(reviews))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.252758\n",
      "         Iterations: 19\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>stars</td>       <th>  Log-Likelihood:    </th> <td> -9395.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>1.880e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>1.884e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Mon, 08 Jan 2024</td>  <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>13:00:22</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  7500</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  7495</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     1</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polarity</th> <td>    6.1631</td> <td>    0.130</td> <td>   47.305</td> <td> 0.000</td> <td>    5.908</td> <td>    6.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1/2</th>      <td>   -1.3268</td> <td>    0.045</td> <td>  -29.574</td> <td> 0.000</td> <td>   -1.415</td> <td>   -1.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2/3</th>      <td>    0.0309</td> <td>    0.036</td> <td>    0.864</td> <td> 0.387</td> <td>   -0.039</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3/4</th>      <td>   -0.0164</td> <td>    0.029</td> <td>   -0.558</td> <td> 0.577</td> <td>   -0.074</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4/5</th>      <td>    0.4341</td> <td>    0.019</td> <td>   22.310</td> <td> 0.000</td> <td>    0.396</td> <td>    0.472</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       stars        & \\textbf{  Log-Likelihood:    } &   -9395.7   \\\\\n",
       "\\textbf{Model:}            &    OrderedModel    & \\textbf{  AIC:               } & 1.880e+04   \\\\\n",
       "\\textbf{Method:}           & Maximum Likelihood & \\textbf{  BIC:               } & 1.884e+04   \\\\\n",
       "\\textbf{Date:}             &  Mon, 08 Jan 2024  & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &      13:00:22      & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &         7500       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Residuals:}     &         7495       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Model:}         &            1       & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{polarity} &       6.1631  &        0.130     &    47.305  &         0.000        &        5.908    &        6.418     \\\\\n",
       "\\textbf{1/2}      &      -1.3268  &        0.045     &   -29.574  &         0.000        &       -1.415    &       -1.239     \\\\\n",
       "\\textbf{2/3}      &       0.0309  &        0.036     &     0.864  &         0.387        &       -0.039    &        0.101     \\\\\n",
       "\\textbf{3/4}      &      -0.0164  &        0.029     &    -0.558  &         0.577        &       -0.074    &        0.041     \\\\\n",
       "\\textbf{4/5}      &       0.4341  &        0.019     &    22.310  &         0.000        &        0.396    &        0.472     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OrderedModel Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   Log-Likelihood:                -9395.7\n",
       "Model:                   OrderedModel   AIC:                         1.880e+04\n",
       "Method:            Maximum Likelihood   BIC:                         1.884e+04\n",
       "Date:                Mon, 08 Jan 2024                                         \n",
       "Time:                        13:00:22                                         \n",
       "No. Observations:                7500                                         \n",
       "Df Residuals:                    7495                                         \n",
       "Df Model:                           1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "polarity       6.1631      0.130     47.305      0.000       5.908       6.418\n",
       "1/2           -1.3268      0.045    -29.574      0.000      -1.415      -1.239\n",
       "2/3            0.0309      0.036      0.864      0.387      -0.039       0.101\n",
       "3/4           -0.0164      0.029     -0.558      0.577      -0.074       0.041\n",
       "4/5            0.4341      0.019     22.310      0.000       0.396       0.472\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = OrderedModel(train['stars'], train['polarity'], distr='logit')\n",
    "\n",
    "res = mod.fit(method='bfgs')\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analys negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to find statements about food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = get_file('tables/reviews_polarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the entity rule to recognize food\n",
    "\n",
    "food = pd.read_csv('food_labels/food.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food[food['description'].str.contains('[a-zA-Z]') == True]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.split().apply(len) <= 2].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.contains('.*,.*,.*', regex=True) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Foods are comma seperated and order is reversed: 'muffins, blueberry' become 'blueberry muffins'\n",
    "\n",
    "food_labels[food_labels.str.contains(', ') == True] = (\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[0]\n",
    ")\n",
    "\n",
    "food_labels[food_labels.str.contains(',') == True] = (\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If label has no plural, create singular form. If label has no singular, create plural \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "inflected_labels = []\n",
    "\n",
    "for label in food_labels:\n",
    "    \n",
    "    doc = nlp(label)\n",
    "\n",
    "    if len(doc) == 1:\n",
    "        if doc[0].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0]._.inflect('NNS'))\n",
    "\n",
    "    if len(doc) == 2:\n",
    "        if doc[1].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NNS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels_inflected = pd.Series(inflected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = pd.concat([food_labels, food_labels_inflected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add food labels to entity ruler\n",
    "\n",
    "food_labels = food_labels  # Remove 'bar' from foods_labels, add 'product'\n",
    "\n",
    "patterns = []\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "\n",
    "for label in food_labels:\n",
    "    patterns.append({'label': 'FOOD', 'pattern': label})\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.to_disk('food_labels/food_patterns.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
    "\n",
    "ruler.from_disk('food_labels/food_patterns.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look for word patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "matcher.add(\n",
    "    'IS_ADJECTIVE',\n",
    "    [\n",
    "        [\n",
    "            {'ENT_TYPE': 'FOOD'},\n",
    "            {'LEMMA': {'IN': ['be', 'taste', 'smell']}},\n",
    "            {'DEP': 'neg', 'OP': '?'},\n",
    "            {'POS': 'ADV', 'OP': '?'},\n",
    "            {'POS': 'ADJ'}\n",
    "        ]\n",
    "    ],\n",
    "    greedy='LONGEST'\n",
    ")\n",
    "\n",
    "def find_food_statements(text):\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    food_statements = []\n",
    "    for _, start, end in matches:\n",
    "        food_statements.append(doc[start: end].text)\n",
    "\n",
    "    if food_statements != []:\n",
    "        return ', '.join(food_statements)\n",
    "    \n",
    "reviews['food_reviews'] = reviews['text'][:1000].apply(lambda x: find_food_statements(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
