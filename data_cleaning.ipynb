{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where does the dataset come from? Download from yelp.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which packages are needed?\n",
    "<b>\n",
    "* spaCy\n",
    "* spacytextblob\n",
    "* LemmInflect\n",
    "* spaCy Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('yelp_dataset/yelp_academic_dataset_business.json') as f:\n",
    "\n",
    "    for line in f:\n",
    "        \n",
    "        json_dict = json.loads(line)\n",
    "\n",
    "        if json_dict['attributes']:\n",
    "            if 'BusinessParking' in json_dict['attributes'].keys():\n",
    "\n",
    "                json_dict['attributes']['BusinessParking'] = eval(json_dict['attributes']['BusinessParking'])\n",
    "\n",
    "        data.append(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.columns = businesses.columns.str.split(('.')).str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for column in businesses.columns:\n",
    "    column = re.sub(r'(\\w)([A-Z])', r'\\1_\\2', column)\n",
    "    column = re.sub(r'Restaurants_', r'', column)\n",
    "    column = re.sub(r'Business_', r'', column)\n",
    "    column = re.sub(r'(Range)([0-9])', r'\\1', column)\n",
    "    columns.append(column.lower())\n",
    "\n",
    "businesses.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.drop(\n",
    "  [\n",
    "    'attributes',\n",
    "    'hair_specializes_in',\n",
    "    'counter_service',\n",
    "    'open24_hours',\n",
    "    'dietary_restrictions',\n",
    "    'accepts_insurance',\n",
    "    'ages_allowed',\n",
    "    'b_yo_bcorkage',\n",
    "    'corkage',\n",
    "    'smoking',\n",
    "    'b_yo_b',\n",
    "    'good_for_dancing',\n",
    "    'coat_check',\n",
    "    'by_appointment_only',\n",
    "    'best_nights',\n",
    "    'music',\n",
    "    'drive_thru',\n",
    "    'accepts_bitcoin',\n",
    "    'dogs_allowed',\n",
    "    'happy_hour',\n",
    "    'wheelchair_accessible',\n",
    "    'good_for_meal',\n",
    "    'ambience',\n",
    "    'business_parking',\n",
    "    'address',\n",
    "    'postal_code',\n",
    "    'hours',\n",
    "    'is_open',\n",
    "    'monday',\n",
    "    'tuesday',\n",
    "    'wednesday',\n",
    "    'thursday',\n",
    "    'friday',\n",
    "    'saturday',\n",
    "    'sunday'\n",
    "  ],\n",
    "  axis=1, errors='ignore', inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses['alcohol'] = businesses['alcohol'].str.replace(\"u'\", \"\").str.replace(\"'\", \"\")\n",
    "businesses['noise_level'] = businesses['noise_level'].str.replace(\"u'\", \"\").str.replace(\"'\", \"\")\n",
    "businesses['attire'] = businesses['attire'].str.replace(\"u'\", \"\").str.replace(\"'\", \"\")\n",
    "businesses['wi_fi'] = businesses['wi_fi'].str.replace(\"u'\", \"\").str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_parking(row):\n",
    "    if row['garage'] == True or row['street'] == True or row['validated'] == True or row['lot'] == True or row['valet'] == True:\n",
    "        return 'True'\n",
    "    if row['garage'] == False or row['street'] == False or row['validated'] == False or row['lot'] == False or row['valet'] == False:\n",
    "        return 'False'\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses['parking_available'] = businesses.apply(check_parking, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.drop(['garage', 'street','validated','lot','valet'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in columns by dummies\n",
    "# Is there shorter code?\n",
    "\n",
    "columns = []\n",
    "stop_list = [\n",
    "    'business_id',\n",
    "    'name',\n",
    "    'city',\n",
    "    'state',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'stars',\n",
    "    'review_count',\n",
    "    'categories',\n",
    "    'monday',\n",
    "    'tuesday',\n",
    "    'wednesday',\n",
    "    'thursday',\n",
    "    'friday',\n",
    "    'saturday',\n",
    "    'sunday'\n",
    "]\n",
    "\n",
    "for column in businesses.columns:\n",
    "    if column not in stop_list:  \n",
    "        columns.append(column)\n",
    "\n",
    "for column in columns:\n",
    "    businesses[column].replace('True', 1, inplace=True)\n",
    "    businesses[column].replace('False', 0, inplace=True)\n",
    "    businesses[column].replace('nan', np.NaN, inplace=True)\n",
    "    businesses[column].replace('None', np.NaN, inplace=True)\n",
    "    businesses[column].replace('none', np.NaN, inplace=True)\n",
    "    businesses[column].replace('casual', 0, inplace=True)\n",
    "    businesses[column].replace('formal', 1, inplace=True)\n",
    "    businesses[column].replace('dressy', 2, inplace=True)\n",
    "    businesses[column].replace('full_bar', 0, inplace=True)\n",
    "    businesses[column].replace('beer_and_wine', 1, inplace=True)\n",
    "    businesses[column].replace('average', 0, inplace=True)\n",
    "    businesses[column].replace('quiet', 1, inplace=True)\n",
    "    businesses[column].replace('loud', 2, inplace=True)\n",
    "    businesses[column].replace('very_loud', 3, inplace=True)\n",
    "    businesses[column].replace('no', 0, inplace=True)\n",
    "    businesses[column].replace('free', 1, inplace=True)\n",
    "    businesses[column].replace('paid', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have created a table with all businesses and the attributes we want to have a look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Businesses in Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennsylvania = businesses[businesses['state'] == 'PA'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurants in Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pennsylvania.dropna(subset='categories', inplace=True)\n",
    "pennsylvania.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a faster ways to do this?\n",
    "\n",
    "categories =[\n",
    "    'Coffee & Tea',\n",
    "    'Bistros',\n",
    "    'Breakfast & Brunch',\n",
    "    'Cafes',\n",
    "    'French',\n",
    "    'Greek',\n",
    "    'Italian',\n",
    "    'Mexican',\n",
    "    'Tacos',\n",
    "    'Egyptian',\n",
    "    'Pizza',\n",
    "    'Soup',\n",
    "    'Sushi Bars',\n",
    "    'Vegetarian',\n",
    "    'Waffles',\n",
    "    'Food',\n",
    "    'Restaurants',\n",
    "    'Bars'\n",
    "]\n",
    "\n",
    "restaurants = pd.DataFrame()\n",
    "\n",
    "for index, item in pennsylvania['categories'].items():\n",
    "\n",
    "    for category in categories:\n",
    "        if category in item:\n",
    "            restaurants = pd.concat([restaurants, pennsylvania[index:index+1]])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tables/restaurants_pennsylvania.csv', 'w') as f:\n",
    "    restaurants.to_csv(f, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have created a table with all restaurants in Pennsylvania and saved it in a .csv for later analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we load the table with all reviews and create a .csv which only contains reviews from restaurants in Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_ids = restaurants['business_id'].to_list()\n",
    "\n",
    "column_names = ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
    "\n",
    "chunks = pd.read_json('yelp_dataset/yelp_academic_dataset_review.json', lines=True, chunksize=100000)\n",
    "\n",
    "with open('tables/reviews_pennsylvania.csv', 'w') as f:\n",
    "    header = ','.join(column_names)\n",
    "    f.write(header + '\\n')\n",
    "\n",
    "    for chunk in chunks:\n",
    "        reviews = pd.DataFrame(chunk)\n",
    "        \n",
    "        reviews[reviews['business_id'].isin(businesses_ids)].to_csv(f, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_file(filename):\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\n",
    "            '''\n",
    "                Do you want to load {0}?\n",
    "                Press 1 to load the file, \n",
    "                press 2 to terminate without loading the file\n",
    "                '''.format(filename)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            user_input = int(user_input)\n",
    "\n",
    "            if user_input == 1:\n",
    "                print('Loading file...')\n",
    "\n",
    "                try:\n",
    "                    f = pd.read_csv(filename)\n",
    "                    print('File loaded...')\n",
    "                    return f\n",
    "                except FileNotFoundError:\n",
    "                    print('File does not exist...')\n",
    "                    break\n",
    "\n",
    "            elif user_input == 2:\n",
    "                print('Terminated without loading the file...')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                print('Invalid input. Please enter either 1 or 2')\n",
    "\n",
    "        except ValueError:\n",
    "            print('Invalid input. Please enter either 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = get_file('tables/restaurants_pennsylvania.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(5, 5))\n",
    "\n",
    "# fig.suptitle('Customer ratings', fontsize=16)\n",
    "\n",
    "sns.barplot(\n",
    "    ax = ax,\n",
    "    x=restaurants['stars'].value_counts().sort_index().index,\n",
    "    y=restaurants['stars'].value_counts().sort_index().values*100/restaurants['stars'].value_counts().sort_index().values.sum(),\n",
    "    color='#FF1A1A'\n",
    ")\n",
    "ax.set(xlabel='Stars', ylabel='No. of businesses in %')\n",
    "ax.set_title('Star ratings');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[[\n",
    "    'stars',\n",
    "    'accepts_credit_cards',\n",
    "    'bike_parking',\n",
    "    'price_range',\n",
    "    'take_out',\n",
    "    'delivery',\n",
    "    'caters',\n",
    "    'wi_fi',\n",
    "    'outdoor_seating',\n",
    "    'has_tv',\n",
    "    'reservations',\n",
    "    'alcohol',\n",
    "    'good_for_kids',\n",
    "    'attire',\n",
    "    'table_service',\n",
    "    'good_for_groups',\n",
    "    'noise_level',\n",
    "    'parking_available'\n",
    "]].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = get_file('tables/reviews_pennsylvania.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "def check_polarity(text):\n",
    "    doc = nlp(text)\n",
    "    return doc._.blob.polarity\n",
    "\n",
    "reviews['polarity'] = reviews['text'][:10000].apply(lambda x: check_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tables/reviews_polarity.csv', 'w') as f:\n",
    "    reviews[:10000].to_csv(f, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = get_file('tables/reviews_polarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews = reviews[reviews['polarity'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analys negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to find statements about food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the entity rule to recognize food\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "food = pd.read_csv('food_labels/food.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food[food['description'].str.contains('[a-zA-Z]') == True]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.split().apply(len) <= 2].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.contains('.*,.*,.*', regex=True) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Foods are comma seperated and order is reversed: 'muffins, blueberry' become 'blueberry muffins'\n",
    "\n",
    "food_labels[food_labels.str.contains(', ') == True] = (\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[0]\n",
    ")\n",
    "\n",
    "food_labels[food_labels.str.contains(',') == True] = (\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If label has no plural, create singular form. If label has no singular, create plural \n",
    "\n",
    "import spacy\n",
    "import lemminflect\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "inflected_labels = []\n",
    "\n",
    "for label in food_labels:\n",
    "    \n",
    "    doc = nlp(label)\n",
    "\n",
    "    if len(doc) == 1:\n",
    "        if doc[0].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0]._.inflect('NNS'))\n",
    "\n",
    "    if len(doc) == 2:\n",
    "        if doc[1].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NNS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels_inflected = pd.Series(inflected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = pd.concat([food_labels, food_labels_inflected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645        italian barley\n",
       "3702        barbecue spice\n",
       "5431               bar bar\n",
       "5547            fudge bars\n",
       "7690         sweet bar-b-q\n",
       "               ...        \n",
       "15881          chunky bars\n",
       "16540           limon bars\n",
       "16663         hazelnut bar\n",
       "16778    blueberry golbars\n",
       "17113             paleobar\n",
       "Length: 538, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_labels[food_labels.str.contains('bar', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add food labels to entity ruler\n",
    "\n",
    "food_labels = food_labels  # Remove 'bar' from foods_labels, add 'product'\n",
    "\n",
    "patterns = []\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "\n",
    "for label in food_labels:\n",
    "    patterns.append({'label': 'FOOD', 'pattern': label})\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30704"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.to_disk('food_labels/food_patterns.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.entityruler.EntityRuler at 0x12d5e4990>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
    "\n",
    "ruler.from_disk('food_labels/food_patterns.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
